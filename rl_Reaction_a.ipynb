{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cCldiJNpWyo"
   },
   "source": [
    "RDKIT installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cagfEL0palg",
    "outputId": "82e2257c-b1a2-49f1-a2ec-2e5f67b6e6a8"
   },
   "outputs": [],
   "source": [
    "!pip install kora q\n",
    "import kora.install.rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrnjmm4bpi7y"
   },
   "source": [
    "Google Drive Mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xzh6pScEpetU",
    "outputId": "a32da589-6a59-4d69-d371-9f6e3bb2c77b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4vK6hXVnnGO"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/gdrive/MyDrive/code/generator')\n",
    "sys.path.append('/content/gdrive/MyDrive/code/predictor')\n",
    "sys.path.append('/content/gdrive/MyDrive/code/reinforce')\n",
    "sys.path.append('/content/gdrive/MyDrive/code/result')\n",
    "sys.path.append('/content/gdrive/MyDrive/code/dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQJvG3FVpqjj"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import RDLogger \n",
    "\n",
    "\n",
    "from models import RNN, OneHotRNN, EarlyStopping\n",
    "from datasets import SmilesDataset, SelfiesDataset, SmilesCollate\n",
    "from functions import decrease_learning_rate, print_update, track_loss, \\\n",
    "     sample_smiles, write_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lH8d3zOnsOeE"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEl3oIEXsm5s"
   },
   "source": [
    "#Load the Pre-trained Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrqIy4MJuZIj"
   },
   "outputs": [],
   "source": [
    "def load_model(model, path):\n",
    "        weights = torch.load(path)\n",
    "        model.load_state_dict(weights)\n",
    "\n",
    "\n",
    "def is_valid(smiles):\n",
    "  mol = Chem.MolFromSmiles(smiles)\n",
    "  if mol is not None and mol.GetNumAtoms()>0:\n",
    "    return smiles\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RDLogger.DisableLog('rdApp.*') # switch off RDKit warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7uZFO77se3V",
    "outputId": "6e9a0ab8-fc63-4556-8c22-58f68f7ad7ea"
   },
   "outputs": [],
   "source": [
    "dataset = SmilesDataset(smiles_file='/content/gdrive/MyDrive/code/generator/pre-trained/chembl_500000.csv', vocab_file ='/content/gdrive/MyDrive/code/generator/pre-trained/vocab_chembl_500000_pat_50000')\n",
    "\n",
    "\n",
    "print(dataset.vocabulary)\n",
    "seed = 0\n",
    "batch_size = 128\n",
    "## seed all RNGs\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"using cuda\")\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "loader = DataLoader(dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    collate_fn=SmilesCollate(dataset.vocabulary))\n",
    "\n",
    "model = RNN(vocabulary=dataset.vocabulary,\n",
    "                rnn_type='GRU',                      # str; RNN type choices=['RNN', 'LSTM', 'GRU']\n",
    "                embedding_size= 128,                 # int; embedding size\n",
    "                hidden_size=512,                     # int; size of language model hidden layers\n",
    "                n_layers=3,                          # int; number of layers in language model\n",
    "                dropout=0,                           # float; amount of dropout (0-1) to apply to model\n",
    "                bidirectional=False,                 # bool; for LSTMs only, train a bidirectional mode\n",
    "                tie_weights=False,\n",
    "                nonlinearity='tanh')\n",
    "# Print model's state_dict\n",
    "#print(\"Model's state_dict:\")\n",
    "#for param_tensor in model.state_dict():\n",
    "    #print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "\n",
    "model_path = '/content/gdrive/MyDrive/code/generator/pre-trained/checkpoint_chembl_500000_pat_50000'\n",
    "load_model(model, model_path)\n",
    "\n",
    "sampled_smiles = []\n",
    "\n",
    "sample_size = 500\n",
    "while len(sampled_smiles) < sample_size:\n",
    "    sampled_smiles.extend(model.sample(batch_size, return_smiles=True))\n",
    "\n",
    "\n",
    "mols = list(filter(is_valid,sampled_smiles)) # Valid\n",
    "print(\"Percentage of validity for pre-trained generator: \" + str((len(mols)/len(sampled_smiles))*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKElYw2ouz5k"
   },
   "source": [
    "#Load Predictor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2TIA_UgvJkx"
   },
   "source": [
    "Cloning of FASTAIv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1I_Md-WlvJlJ",
    "outputId": "e3859d82-80d9-41c2-f16e-0c928981627e"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/fastai/fastai1.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQYIYWVjpAVt"
   },
   "outputs": [],
   "source": [
    "!mv /content/fastai1 /content/fastai_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q142eirNqKEN"
   },
   "outputs": [],
   "source": [
    "!mv /content/fastai_pred1/fastai /content/fastai_pred1/fastai_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kvrJYzYvJlK"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/fastai_pred1')\n",
    "sys.path.append('/content/fastai_pred1/fastai_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YB7k-H_Yviuz",
    "outputId": "1239fb45-575c-4e03-8853-ac43b2900e7b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from fastai_pred import *\n",
    "from fastai_pred.text import *\n",
    "from fastai_pred.vision import *\n",
    "from fastai_pred.imports import *\n",
    "\n",
    "import numpy as np\n",
    "import threading\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFS-8L51v18S"
   },
   "outputs": [],
   "source": [
    "import tl_Predictor_Reaction_a\n",
    "from tl_Predictor_Reaction_a import pred_init, train_reg, test_performance, test_performance, predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UPa2F6YwAM6"
   },
   "outputs": [],
   "source": [
    "#Parameter defining\n",
    "seed_tl = 1234\n",
    "batch_size = 128\n",
    "filename = pd.read_csv('/content/gdrive/MyDrive/code/dataset/Reaction_a.csv')\n",
    "augm = 100\n",
    "drp_out = 0.0 \n",
    "sigm_g = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "RxhbJt7Cxwqq",
    "outputId": "fd0f0b08-9d5c-433a-c190-bf3fcf58a468"
   },
   "outputs": [],
   "source": [
    "#Loading of pre-trained weight using Transfer Learning\n",
    "reg_learner_pre, train_aug , valid = pred_init(seed_tl, batch_size, filename, current_path, augm, drp_out, sigm_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "3NJ-pswFyeK5",
    "outputId": "b50b259f-e8e4-4eda-f2bb-ce0620eb390c"
   },
   "outputs": [],
   "source": [
    "test_rmse = test_performance(seed_tl, batch_size, filename, train_aug, valid, current_path, drp_out, sigm_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-xpocbmuuWj"
   },
   "source": [
    "#Fragment Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fe7z9ePMz0zx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import pickle\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2V_nNSctiaU"
   },
   "outputs": [],
   "source": [
    "import functions_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ej_M5975tejV"
   },
   "outputs": [],
   "source": [
    "from functions_rl import generate_allfragments, join_frag, usable_frag, permute, gen_firstatom_frag, plot_hist, tensor_to_array, canonical_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzFlVV7xzLuM"
   },
   "outputs": [],
   "source": [
    "def add_othercomponents(smile, components = 'C(C(C(F)(F)S(=O)(=O)F)(F)F)(C(F)(F)F)(F)F.CC(C)(C)N=P(N1CCCC1)(N2CCCC2)N3CCCC3'):\n",
    "    return smile + '.' + components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bnt3rkqju2P"
   },
   "outputs": [],
   "source": [
    "## If you want combinatorial evaluation result then run this section\n",
    "\n",
    "\n",
    "base_list = ['C1CCC2=NCCCN2CC1', 'CN1CCCN2CCCN=C12', 'CC(C)(C)N=C(N(C)C)N(C)C', 'CC(C)(C)N=P(N1CCCC1)(N2CCCC2)N3CCCC3']\n",
    "fluor_list = ['c1cc(ccc1S(=O)(=O)F)Cl', 'c1ccnc(c1)S(=O)(=O)F', 'c1cc(ccc1C(F)(F)F)S(=O)(=O)F', 'c1cc(ccc1[N+](=O)[O-])S(=O)(=O)F', 'C(C(C(F)(F)S(=O)(=O)F)(F)F)(C(F)(F)F)(F)F']\n",
    "base_name_list = ['B1','B2','B3','B4']\n",
    "fluor_name_list =  ['SF1','SF2','SF3','SF4','SF5']\n",
    "\n",
    "def combinatorial_evaluation(alc_list, base_list, fluor_list, tl_Predictor_Reaction_a):\n",
    "    alc_list =  np.asarray(alc_list, dtype=np.str_)\n",
    "    SF_base_pred_list = []\n",
    "    for i in range(len(fluor_list)):\n",
    "        for j in range(len(base_list)):\n",
    "            current_list = []\n",
    "            for k in range(len(alc_list)):\n",
    "                #x = alc_list[k] + '.' + fluor_list[i] + '.' + base_list[j]\n",
    "                #print(x)\n",
    "                current_list.append(alc_list[k] + '.' + fluor_list[i] + '.' + base_list[j])\n",
    "            \n",
    "            smiles, prediction = tl_Predictor_Reaction_a.predictor(current_list, seed_tl, batch_size, filename, train_aug, valid, current_path, drp_out, sigm_g)\n",
    "            SF_base_pred_list.append(tensor_to_array(prediction).mean())\n",
    "            print(\"Fluorinating agent: \", fluor_list[i])\n",
    "            print(\"Base:\", base_list[j])\n",
    "            plot_hist(prediction, 1)\n",
    "\n",
    "    return SF_base_pred_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnVm7QLv3Zcn"
   },
   "outputs": [],
   "source": [
    "def novelty_score(mols,ref_mols): \n",
    "    return set.difference(mols,ref_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pX0suHVdwLq"
   },
   "outputs": [],
   "source": [
    "def dataframe(smile, pred_val):\n",
    "  smile_df = pd.DataFrame(smile, columns = ['smiles'])\n",
    "  prediction_array = list(tensor_to_array(pred_val))\n",
    "  prediction_df = pd.DataFrame(prediction_array, columns = ['predicted_value'])\n",
    "  smile_pred_df  = pd.concat([smile_df,prediction_df], axis =1)\n",
    "  return smile_pred_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wp9uKXKg3lax",
    "outputId": "23124ab5-6713-4347-bb81-91284169a4a2"
   },
   "outputs": [],
   "source": [
    "smiles_train_file= pd.read_csv('/content/gdrive/MyDrive/code/generator/pre-trained/chembl_500000.csv', header= None)\n",
    "smiles_train_file.columns = ['smiles_train']\n",
    "#reference dataset\n",
    "obj_ref = list(set(smiles_train_file.smiles_train))\n",
    "print(len(obj_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agTPQDWHzRJF"
   },
   "outputs": [],
   "source": [
    "def estimate_and_update(gen, tl_Predictor_Reaction_a, n_to_generate, core_smi='OC(*)', **kwargs):\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    seed_value = rng.integers(low = 10000)\n",
    "\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "    torch.backends.cudnn.deterministic = True  #needed\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    generated = []\n",
    "    generated_mol = []\n",
    "    pbar = tqdm(range(n_to_generate))\n",
    "    for i in pbar:\n",
    "        pbar.set_description(\"Generating molecules...\")\n",
    "        no_sample = 1\n",
    "        sampled_smiles = gen.sample(no_sample, max_len=100, return_smiles=True)\n",
    "        generated.append(sampled_smiles)\n",
    "        \n",
    "    generated = [ y for ys in generated for y in ys]\n",
    "  \n",
    "    generated_novel = []\n",
    "    \n",
    "    x = 0\n",
    "    for j in range(len(generated)):\n",
    "        if_smile = Chem.MolFromSmiles(generated[j])\n",
    "        if if_smile is not None:\n",
    "            x+=1\n",
    "            frag = gen_firstatom_frag(generated[j])\n",
    "            molecule = join_frag(core_smi, frag)\n",
    "            #print(molecule)\n",
    "            generated_novel.append(generated[j])\n",
    "            generated_mol.append(molecule)\n",
    "            \n",
    "    if x==0:\n",
    "        return [], []\n",
    "\n",
    "    sanitized = canonical_smiles(generated_mol, sanitize=False, throw_warning=False)[:-1]\n",
    "    unique_smiles = list(np.unique(sanitized))[1:]\n",
    "\n",
    "    unique_components = []\n",
    "    for i in range(len(unique_smiles)):\n",
    "        unique_components.append(add_othercomponents(unique_smiles[i]))\n",
    "\n",
    "\n",
    "    smiles, prediction = tl_Predictor_Reaction_a.predictor(unique_components, seed_tl, batch_size, filename, train_aug, valid, current_path, drp_out, sigm_g)\n",
    "    \n",
    "    novel_mols = novelty_score(set(generated_novel), set(obj_ref))\n",
    "\n",
    "    print(\"Total number of valid fragment backbones generated:\", x)\n",
    "    print(\"Percentage of validity:\", (x/n_to_generate)*100)\n",
    "    print(\"Percentage of uniqueness\", (len(set(generated_novel))/n_to_generate)*100)\n",
    "    print(\"Percentage of novelty\", (len(novel_mols)/n_to_generate)*100)                                            \n",
    "    plot_hist(prediction, n_to_generate)\n",
    "\n",
    "    return smiles, prediction, unique_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITnTXwXv0ulj"
   },
   "source": [
    "**Unbiased Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "IrLGvj2G0N-6",
    "outputId": "8d9ecbeb-3108-4ac2-afb0-e284b057d9c1"
   },
   "outputs": [],
   "source": [
    "smiles_unbiased, prediction_unbiased, molecule_list =estimate_and_update(model, tl_Predictor_Reaction_a,\n",
    "                                                              n_to_generate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1D3HuKupZrva"
   },
   "outputs": [],
   "source": [
    "smile_pred_unbiased_df = dataframe(smiles_unbiased, prediction_unbiased)\n",
    "smile_pred_unbiased_df.to_csv('/content/gdrive/MyDrive/code/result/unbiased_Recation_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ScqWqXS1q9Xa",
    "outputId": "0a5dda5c-086c-4133-9cdb-d49488fb1cbc"
   },
   "outputs": [],
   "source": [
    "## If you want to see the results of combinatorial evaluation, run this section\n",
    "pred_value_all_base_sf = combinatorial_evaluation(molecule_list, base_list, fluor_list, tl_Predictor_Reaction_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dN4Uc1nG00Lz"
   },
   "source": [
    "**Biased Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjKrUp3m1WMa"
   },
   "outputs": [],
   "source": [
    "import fragment_rl_Reaction_a\n",
    "from fragment_rl_Reaction_a import Reinforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTJF0PXQ0x1S"
   },
   "outputs": [],
   "source": [
    "n_to_generate = 500\n",
    "n_policy_replay = 10\n",
    "n_policy = 5\n",
    "n_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHOQnjhF07Cz"
   },
   "outputs": [],
   "source": [
    "def simple_moving_average(previous_values, new_value, ma_window_size=10):\n",
    "    value_ma = np.sum(previous_values[-(ma_window_size-1):]) + new_value\n",
    "    value_ma = value_ma/(len(previous_values[-(ma_window_size-1):]) + 1)\n",
    "    return value_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Al3L5SzW093L"
   },
   "outputs": [],
   "source": [
    "def get_reward(smiles, tl_Predictor_Reaction_a, invalid_reward=0.0):\n",
    "    rewards = np.zeros([len(smiles)])\n",
    "    \n",
    "    mol, prop = tl_Predictor_Reaction_a.predictor(smiles, seed_tl, batch_size, filename, train_aug, valid, current_path, drp_out, sigm_g)\n",
    "\n",
    "    for i in range(len(smiles)):\n",
    "        if smiles[i] is '':\n",
    "            rewards[i] = -2\n",
    "        else:\n",
    "            pred = tensor_to_array(prop)\n",
    "            if pred[i] != pred[i]:\n",
    "                rewards.append(invalid_reward)\n",
    "            else:\n",
    "                t=int((pred[i]-50)/5)\n",
    "                if t<0:\n",
    "                    t=0\n",
    "                rewards[i] = ((t*2)+1)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHOSEvrSyTkB"
   },
   "outputs": [],
   "source": [
    "def get_pred_val(smiles, tl_Predictor_Reaction_a):\n",
    "    generated_novel = []\n",
    "    for j in range(len(smiles)):\n",
    "        if_smile = Chem.MolFromSmiles(smiles[j])\n",
    "        if if_smile is not None:\n",
    "            generated_novel.append(smiles[j])  \n",
    "    unique_components = list(np.unique(generated_novel))\n",
    "    mol, prop = tl_Predictor_Reaction_a.predictor(unique_components, seed_tl, batch_size, filename, train_aug, valid, current_path, drp_out, sigm_g)\n",
    "    prop_new = tensor_to_array(prop)\n",
    "    return prop_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPckrKsT1BOj"
   },
   "outputs": [],
   "source": [
    "RL_max = Reinforcement(model, tl_Predictor_Reaction_a, get_reward, get_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "be9MUo891D8C"
   },
   "outputs": [],
   "source": [
    "rewards_max = []\n",
    "rl_losses_max = []\n",
    "pred_Reinforce_max_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lyzybBkD1Iay",
    "outputId": "e04fc2d0-56d6-4597-94c2-830a03b6b8ae"
   },
   "outputs": [],
   "source": [
    "for i in range(n_iterations):\n",
    "    for j in trange(n_policy, desc='Policy gradient...'):\n",
    "        cur_reward, cur_loss, cur_pred = RL_max.policy_gradient(dataset.vocabulary)\n",
    "        pred_Reinforce_max_plot.append(cur_pred)\n",
    "        rewards_max.append(simple_moving_average(rewards_max, cur_reward)) \n",
    "        rl_losses_max.append(simple_moving_average(rl_losses_max, cur_loss))\n",
    "        \n",
    "    plt.plot(rewards_max)\n",
    "    plt.xlabel('Training iteration')\n",
    "    plt.ylabel('Average reward')\n",
    "    plt.show()\n",
    "    plt.plot(rl_losses_max)\n",
    "    plt.xlabel('Training iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    plt.plot(pred_Reinforce_max_plot)\n",
    "    plt.xlabel('Training iteration')\n",
    "    plt.ylabel('Predicted value')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    smiles_cur, prediction_cur, molecule_list_ =estimate_and_update(RL_max.generator, tl_Predictor_Reaction_a,\n",
    "                                                    n_to_generate=n_to_generate)\n",
    "    print('Sample trajectories:')\n",
    "    for sm in smiles_cur[:5]:\n",
    "        print(sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "1I3ncbv01L3N",
    "outputId": "e84262d4-3f5c-4fa0-da9c-210e34ba1fdd"
   },
   "outputs": [],
   "source": [
    "smiles_bias500, prediction_bias500, molecule_list_bias_500 =estimate_and_update(RL_max.generator, tl_Predictor_Reaction_a, n_to_generate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9Nx6OQzicMq"
   },
   "outputs": [],
   "source": [
    "smile_pred_biased_df = dataframe(smiles_bias500, prediction_bias500)\n",
    "smile_pred_biased_df.to_csv('/content/gdrive/MyDrive/code/result/biased_Recation_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YUithszBxqx9",
    "outputId": "8628b2b0-18c1-46d5-b26a-95a53979ec11"
   },
   "outputs": [],
   "source": [
    "## If you want to see the results of combinatorial evaluation, run this section\n",
    "pred_value_all_base_sf_bias = combinatorial_evaluation(molecule_list_bias_500, base_list, fluor_list, tl_Predictor_Reaction_a)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
